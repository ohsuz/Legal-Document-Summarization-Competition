{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a04b4bc-827d-455c-baf1-6a908b3abbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: easydict in /opt/conda/lib/python3.7/site-packages (1.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95f1ec09-f191-416f-8a1a-89c66b1341a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a0a117e-9d2c-49d8-af46-f173a8816380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, args, data, mode):\n",
    "        self.data = data\n",
    "        self.data_dir = args.data_dir\n",
    "        self.mode = mode\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
    "        self.inputs, self.labels = self.data_loader()\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading ' + self.mode + ' dataset..')\n",
    "        if os.path.isfile(os.path.join(self.data_dir, self.mode + '_X.pt')):\n",
    "            inputs = torch.load(os.path.join(self.data_dir, self.mode + '_X.pt'))\n",
    "            labels = torch.load(os.path.join(self.data_dir, self.mode + '_Y.pt'))\n",
    "\n",
    "        else:\n",
    "            df = self.data\n",
    "            inputs = pd.DataFrame(columns=['src'])\n",
    "            labels = pd.DataFrame(columns=['trg'])\n",
    "            inputs['src'] =  df['article_original']\n",
    "\n",
    "            if self.mode != \"test\":\n",
    "                labels['trg'] =  df['extractive']\n",
    "\n",
    "            # Preprocessing\n",
    "            inputs, labels = self.preprocessing(inputs, labels)\n",
    "            print(\"preprocessing\")\n",
    "\n",
    "            # Save data\n",
    "            torch.save(inputs, os.path.join(self.data_dir, self.mode + '_X.pt'))\n",
    "            torch.save(labels, os.path.join(self.data_dir, self.mode + '_Y.pt'))\n",
    "\n",
    "        inputs = inputs.values\n",
    "        labels = labels.values\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def pad(self, data, pad_id, max_len):\n",
    "        padded_data = data.map(lambda x : torch.cat([x, torch.tensor([pad_id] * (max_len - len(x)), dtype=torch.int64)]))\n",
    "        return padded_data\n",
    "    \n",
    "    def tokenize(self, x):\n",
    "        result = [self.tokenizer.encode(x[i], add_special_tokens=True) for i in range(len(x))]\n",
    "        result_concat = list(chain.from_iterable(result))\n",
    "        \n",
    "        if len(result_concat) <= 512:\n",
    "            return torch.tensor(result_concat)\n",
    "            \n",
    "        else:\n",
    "            length_sum = 0\n",
    "            for sen_token in result:\n",
    "                length_sum += len(sen_token)\n",
    "                \n",
    "            return torch.tensor(list(chain.from_iterable([self.tokenizer.encode(x[i], max_length = int(512 / len(x)), add_special_tokens=True) for i in range(len(x))])))\n",
    "\n",
    "\n",
    "    def preprocessing(self, inputs, labels):\n",
    "        print('Preprocessing ' + self.mode + ' dataset..')\n",
    "\n",
    "        # Encoding original text\n",
    "        inputs['src'] = inputs['src'].map(self.tokenize)\n",
    "        # inputs['src'] = inputs['src'].map(lambda x: torch.tensor(list(chain.from_iterable([self.tokenizer.encode(x[i], max_length = int(512 / len(x)), add_special_tokens=True) for i in range(len(x))]))))\n",
    "        inputs['clss'] = inputs.src.map(lambda x : torch.cat([torch.where(x == 2)[0], torch.tensor([len(x)])]))\n",
    "        inputs['segs'] = inputs.clss.map(lambda x : torch.tensor(list(chain.from_iterable([[0] * (x[i+1] - x[i]) if i % 2 == 0 else [1] * (x[i+1] - x[i]) for i, val in enumerate(x[:-1])]))))\n",
    "        inputs['clss'] = inputs.clss.map(lambda x : x[:-1])\n",
    "        \n",
    "        # Padding\n",
    "        max_encoding_len = max(inputs.src.map(lambda x: len(x)))\n",
    "        max_label_len = max(inputs.clss.map(lambda x: len(x)))\n",
    "        inputs['src'] = self.pad(inputs.src, 0, max_encoding_len)\n",
    "        inputs['segs'] = self.pad(inputs.segs, 0, max_encoding_len)\n",
    "        inputs['clss'] = self.pad(inputs.clss, -1, max_label_len)\n",
    "        inputs['mask'] = inputs.src.map(lambda x: ~ (x == 0))\n",
    "        inputs['mask_clss'] = inputs.clss.map(lambda x: ~ (x == -1))\n",
    "\n",
    "        # Binarize label {Extracted sentence : 1, Not Extracted sentence : 0}\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            labels = labels['trg'].map(lambda  x: torch.tensor([1 if i in x else 0 for i in range(max_label_len)]))\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'test':\n",
    "            return [self.inputs[index][i] for i in range(5)]\n",
    "        else:\n",
    "            return [self.inputs[index][i] for i in range(5)], self.labels[index]\n",
    "\n",
    "\n",
    "def get_train_loaders(args):\n",
    "    \"\"\"\n",
    "        define train/validation pytorch dataset & loader\n",
    "\n",
    "        Returns:\n",
    "            train_loader: pytorch data loader for train data\n",
    "            val_loader: pytorch data loader for validation data\n",
    "    \"\"\"\n",
    "    # get data from json\n",
    "    with open(os.path.join(args.data_dir, \"train.json\"), \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        data = pd.read_json(f) \n",
    "    train_df = pd.DataFrame(data)\n",
    "    \n",
    "    if args.train_kfold:\n",
    "        kf = KFold(n_splits=5)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(train_df)):\n",
    "            if args.fold != fold:\n",
    "                continue\n",
    "            train_data = train_df.iloc[train_idx]\n",
    "            val_data = train_df.iloc[val_idx]        \n",
    "    else:\n",
    "        train_data, val_data = train_test_split(train_df, test_size=0.1, random_state=args.seed)\n",
    "    \n",
    "    # get train & valid dataset from dataset.py\n",
    "    train_dataset = CustomDataset(args, train_data, mode='train')\n",
    "    val_dataset = CustomDataset(args, val_data, mode='valid')\n",
    "\n",
    "    # define data loader based on each dataset\n",
    "    train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                                  batch_size=args.batch_size,\n",
    "                                  num_workers=args.num_workers,\n",
    "                                  pin_memory=True,\n",
    "                                  drop_last=False,\n",
    "                                  shuffle=True)\n",
    "    val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                                batch_size=args.batch_size,\n",
    "                                num_workers=args.num_workers,\n",
    "                                pin_memory=True,\n",
    "                                drop_last=False,\n",
    "                                shuffle=False)\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62629093-ceab-42db-ba44-bb1711bc21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "# 설정\n",
    "config['seed'] = 981201\n",
    "config['device'] = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "config['data_dir'] = '/opt/ml/Legal-Document-Summarization/data'\n",
    "config['model_name'] = 'klue/bert-base'\n",
    "config['batch_size'] = 32\n",
    "config['num_workers']= 4\n",
    "config['train_kfold']= False\n",
    "\n",
    "\n",
    "args = easydict.EasyDict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "145d708e-ba3c-4189-99be-dd5968e6a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(args.data_dir, \"train.json\"), \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        data = pd.read_json(f) \n",
    "train_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43490160-6832-4b1d-8a8e-338ae1e73b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>extractive</th>\n",
       "      <th>article_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196524</td>\n",
       "      <td>[13, 14, 15]</td>\n",
       "      <td>[[1] 의용 부동산등기법 제35조 제1항,, 제60조 제1항은 등기를 신청함에는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106984</td>\n",
       "      <td>[1, 2, 4]</td>\n",
       "      <td>[가. 주택개량을 위하여 조합원들이 스스로 결성한 주택개량재개발조합이 실시하는 재개...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190919</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[금원의 목적 내지 성질상 국가나 지방자치단체와 특정인 사이에서만 수수,, 결제되어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110573</td>\n",
       "      <td>[0, 2, 5]</td>\n",
       "      <td>[가. 자동차대여업자의 직원으로서는 운전면허 없는 운전자가 위조된 운전면허증의 복사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156698</td>\n",
       "      <td>[0, 2, 3]</td>\n",
       "      <td>[소외회사의 평리사 6명을 제쳐 놓고 대표이사 3명만의 결의에 의하여 동회사의 대표...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    extractive                                   article_original\n",
       "0  196524  [13, 14, 15]  [[1] 의용 부동산등기법 제35조 제1항,, 제60조 제1항은 등기를 신청함에는 ...\n",
       "1  106984     [1, 2, 4]  [가. 주택개량을 위하여 조합원들이 스스로 결성한 주택개량재개발조합이 실시하는 재개...\n",
       "2  190919     [1, 2, 3]  [금원의 목적 내지 성질상 국가나 지방자치단체와 특정인 사이에서만 수수,, 결제되어...\n",
       "3  110573     [0, 2, 5]  [가. 자동차대여업자의 직원으로서는 운전면허 없는 운전자가 위조된 운전면허증의 복사...\n",
       "4  156698     [0, 2, 3]  [소외회사의 평리사 6명을 제쳐 놓고 대표이사 3명만의 결의에 의하여 동회사의 대표..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "adea0aa0-88a0-4d0b-b6d2-ce833a1533d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pd.DataFrame(columns=['src'])\n",
    "labels = pd.DataFrame(columns=['trg'])\n",
    "inputs['src'] =  train_df['article_original']\n",
    "labels['trg'] =  train_df['extractive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f25ee71f-280b-434a-89db-422adeacd539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[1] 의용 부동산등기법 제35조 제1항,, 제60조 제1항은 등기를 신청함에는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[가. 주택개량을 위하여 조합원들이 스스로 결성한 주택개량재개발조합이 실시하는 재개...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[금원의 목적 내지 성질상 국가나 지방자치단체와 특정인 사이에서만 수수,, 결제되어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[가. 자동차대여업자의 직원으로서는 운전면허 없는 운전자가 위조된 운전면허증의 복사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[소외회사의 평리사 6명을 제쳐 놓고 대표이사 3명만의 결의에 의하여 동회사의 대표...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 src\n",
       "0  [[1] 의용 부동산등기법 제35조 제1항,, 제60조 제1항은 등기를 신청함에는 ...\n",
       "1  [가. 주택개량을 위하여 조합원들이 스스로 결성한 주택개량재개발조합이 실시하는 재개...\n",
       "2  [금원의 목적 내지 성질상 국가나 지방자치단체와 특정인 사이에서만 수수,, 결제되어...\n",
       "3  [가. 자동차대여업자의 직원으로서는 운전면허 없는 운전자가 위조된 운전면허증의 복사...\n",
       "4  [소외회사의 평리사 6명을 제쳐 놓고 대표이사 3명만의 결의에 의하여 동회사의 대표..."
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8fce8916-3da8-47b9-8d2b-013247d7e95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[1] 의용 부동산등기법 제35조 제1항,',\n",
       " '제60조 제1항은 등기를 신청함에는 등기원인을 증명하는 서면을 제출하여야 하고,',\n",
       " '등기관리가 등기를 완료한 때에는 등기원인을 증명하는 서면',\n",
       " '또는 신청서 부본에 등기번호,',\n",
       " '신청서 수부(受附) 연월일,',\n",
       " '수부번호(受附番號),',\n",
       " '순위번호 및 등기제(登記濟)의 뜻을 기재하고,',\n",
       " '등기소의 인을 압날하여 이를 등기권리자에게 환부하여야 한다고 규정하고 있다.',\n",
       " '그러므로 매도증서에 위 규정에 따른 등기번호,',\n",
       " '등기순위, 등기제 등의 기재와 등기소인이 날인되어 있는 사실이 인정된다면,',\n",
       " '이는 등기 신청 시 등기원인을 증명하는 서면으로 제출되었다가 등기관리가 등기를 완료하고',\n",
       " '등기권리자에게 되돌려준 것으로 보지 않을 수 없다.',\n",
       " '따라서 특별한 사정이 없는 한 그 서면에 기재된 부동산에 관하여 그 기재의 등기번호와 순위번호에 따른 등기가 마쳐졌다고 인정하여야 한다.',\n",
       " '[2] 민사소송법 제356조 제1항은 문서의 작성방식과 취지에 의하여 공무원이 직무상 작성한 것으로 인정한 때에는 이를 진정한 공문서로 추정한다고 규정하고 있으나,',\n",
       " '위조 또는 변조 등 특별한 사정이 있다고 볼 만한 반증이 있는 경우에는 위와 같은 추정은 깨어진다.',\n",
       " '[3] 매도증서 등에 등기소의 등기제(登記濟)의 기재가 첨가됨으로써 사문서와 공문서로 구성된 문서는 공증에 관한 문서와는 달라 공문서 부분 성립이 인정된다고 하여 바로 사문서 부분인 매도증서 자체의 진정성립이 추정되거나 인정될 수는 없다.']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "455c7748-2b96-4a36-ad92-e720407f1f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[13, 14, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 2, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 2, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            trg\n",
       "0  [13, 14, 15]\n",
       "1     [1, 2, 4]\n",
       "2     [1, 2, 3]\n",
       "3     [0, 2, 5]\n",
       "4     [0, 2, 3]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638bd335-b9cd-4415-8d79-eff4e4d952ef",
   "metadata": {},
   "source": [
    "## 1. Preprocessing 1단계 : Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "693f223a-3376-4997-8f8d-859833856993",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1ac92863-2b02-4723-a922-18c2491439ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    result = [tokenizer.encode(x[i], add_special_tokens=True) for i in range(len(x))]\n",
    "    result_concat = list(chain.from_iterable(result))\n",
    "\n",
    "    if len(result_concat) <= 512:\n",
    "        return torch.tensor(result_concat)\n",
    "    \n",
    "    else:\n",
    "        length_sum = 0\n",
    "        for sen_token in result:\n",
    "            length_sum += len(sen_token)\n",
    "\n",
    "        return torch.tensor(list(chain.from_iterable([tokenizer.encode(x[i], max_length = int(512 * (len(result[i]) / length_sum)-1), add_special_tokens=True) for i in range(len(x))])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1dee17a8-ebb5-42b6-8c0d-25050fafa945",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['src'] = inputs['src'].map(tokenize)\n",
    "\n",
    "# inputs['src'] = inputs['src'].map(lambda x: torch.tensor(list(chain.from_iterable([tokenizer.encode(x[i], max_length = int(512 / len(x)), add_special_tokens=True, truncation=True) for i in range(len(x))]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9045e315-2869-4f39-a296-b239feed99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(inputs['src']):\n",
    "    if len(i) > 512:\n",
    "        print(len(i))\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "65ecba37-230e-4f99-9580-b116ddf7735b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] [ 1 ] 의용 부동산등기법 제35조 제1항, [SEP] [CLS] 제60조 제1항은 등기를 신청함에는 등기원인을 증명하는 서면을 제출하여야 하고, [SEP] [CLS] 등기관리가 등기를 완료한 때에는 등기원인을 증명하는 서면 [SEP] [CLS] 또는 신청서 부본에 등기번호, [SEP] [CLS] 신청서 수부 ( 受 [UNK] ) 연월일, [SEP] [CLS] 수부번호 ( 受 [UNK] [UNK] [UNK] ), [SEP] [CLS] 순위번호 및 등기제 ( [UNK] 記 濟 ) 의 뜻을 기재하고, [SEP] [CLS] 등기소의 인을 압날하여 이를 등기권리자에게 환부하여야 한다고 규정하고 있다. [SEP] [CLS] 그러므로 매도증서에 위 규정에 따른 등기번호, [SEP] [CLS] 등기순위, 등기제 등의 기재와 등기소인이 날인되어 있는 사실이 인정된다면, [SEP] [CLS] 이는 등기 신청 시 등기원인을 증명하는 서면으로 제출되었다가 등기관리가 등기를 완료하고 [SEP] [CLS] 등기권리자에게 되돌려준 것으로 보지 않을 수 없다. [SEP] [CLS] 따라서 특별한 사정이 없는 한 그 서면에 기재된 부동산에 관하여 그 기재의 등기번호와 순위번호에 따른 등기 [SEP] [CLS] [ 2 ] 민사소송법 제356조 제1항은 문서의 작성방식과 취지에 의하여 공무원이 직무상 작성한 것 [SEP] [CLS] 위조 또는 변조 등 특별한 사정이 있다고 볼 만한 반증이 있는 경우에는 위와 같은 추정은 깨어진다. [SEP] [CLS] [ 3 ] 매도증서 등에 등기소의 등기제 ( [UNK] 記 濟 ) 의 기재가 첨가됨으로써 사문서와 공문서로 [SEP]'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['src'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "168e6355-2483-4b79-9f2b-4ebbda1c4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['clss'] = inputs.src.map(lambda x : torch.cat([torch.where(x == 2)[0], torch.tensor([len(x)])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ccf3e798-b3a4-4b1e-8e2f-e4c08cbaf01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  17,  46,  66,  77,  88, 100, 119, 146, 161, 188, 215, 235, 276,\n",
       "        326, 356, 432])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['clss'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4c3c03bf-e2bc-4a45-ac20-de09c18378d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['segs'] = inputs.clss.map(lambda x : torch.tensor(list(chain.from_iterable([[0] * (x[i+1] - x[i]) if i % 2 == 0 else [1] * (x[i+1] - x[i]) for i, val in enumerate(x[:-1])]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8a93e3f3-7f86-4654-98ca-2f8d3f09bdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['segs'][0] # 한 문장 : 2부터 시작 ~ 3에서 끝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d959e8dd-4c82-4957-9122-e88f40598454",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['clss'] = inputs.clss.map(lambda x : x[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "30eb0899-a18f-41a5-89b4-5552dcd296e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  17,  46,  66,  77,  88, 100, 119, 146, 161, 188, 215, 235, 276,\n",
       "        326, 356])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['clss'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876f7d32-9d09-463f-9bb1-e54b186e09fc",
   "metadata": {},
   "source": [
    "## 2. Preprocessing 2단계 : Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d4ba3aa0-6718-4545-a7f6-4d77468ddb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 50\n"
     ]
    }
   ],
   "source": [
    "max_encoding_len = max(inputs.src.map(lambda x: len(x)))\n",
    "max_label_len = max(inputs.clss.map(lambda x: len(x)))\n",
    "\n",
    "print(max_encoding_len, max_label_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8bf29a41-89f9-4623-b0fd-8d542124ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(data, pad_id, max_len):\n",
    "    padded_data = data.map(lambda x : torch.cat([x, torch.tensor([pad_id] * (max_len - len(x)), dtype=torch.int64)]))\n",
    "    return padded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0e23958c-dffa-4da7-a8f8-56c00e2688ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['src'] = pad(inputs.src, 0, max_encoding_len)\n",
    "inputs['segs'] = pad(inputs.segs, 0, max_encoding_len)\n",
    "inputs['clss'] = pad(inputs.clss, -1, max_label_len)\n",
    "inputs['mask'] = inputs.src.map(lambda x: ~ (x == 0))\n",
    "inputs['mask_clss'] = inputs.clss.map(lambda x: ~ (x == -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e4c64886-cd54-4cd5-9132-db0c6e00ac68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>clss</th>\n",
       "      <th>segs</th>\n",
       "      <th>mask</th>\n",
       "      <th>mask_clss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tensor(2), tensor(63), tensor(21), tensor(64)...</td>\n",
       "      <td>[tensor(0), tensor(17), tensor(46), tensor(66)...</td>\n",
       "      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[tensor(2), tensor(543), tensor(18), tensor(40...</td>\n",
       "      <td>[tensor(0), tensor(71), tensor(126), tensor(17...</td>\n",
       "      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[tensor(2), tensor(641), tensor(2252), tensor(...</td>\n",
       "      <td>[tensor(0), tensor(20), tensor(54), tensor(127...</td>\n",
       "      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[tensor(2), tensor(543), tensor(18), tensor(41...</td>\n",
       "      <td>[tensor(0), tensor(70), tensor(84), tensor(167...</td>\n",
       "      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[tensor(2), tensor(6954), tensor(6166), tensor...</td>\n",
       "      <td>[tensor(0), tensor(82), tensor(109), tensor(17...</td>\n",
       "      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24022</th>\n",
       "      <td>[tensor(2), tensor(9679), tensor(2052), tensor...</td>\n",
       "      <td>[tensor(0), tensor(88), tensor(124), tensor(13...</td>\n",
       "      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24023</th>\n",
       "      <td>[tensor(2), tensor(63), tensor(21), tensor(64)...</td>\n",
       "      <td>[tensor(0), tensor(46), tensor(92), tensor(128...</td>\n",
       "      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24024</th>\n",
       "      <td>[tensor(2), tensor(4461), tensor(7315), tensor...</td>\n",
       "      <td>[tensor(0), tensor(32), tensor(95), tensor(112...</td>\n",
       "      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24025</th>\n",
       "      <td>[tensor(2), tensor(63), tensor(21), tensor(64)...</td>\n",
       "      <td>[tensor(0), tensor(18), tensor(31), tensor(52)...</td>\n",
       "      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24026</th>\n",
       "      <td>[tensor(2), tensor(20223), tensor(2520), tenso...</td>\n",
       "      <td>[tensor(0), tensor(8), tensor(24), tensor(49),...</td>\n",
       "      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "      <td>[tensor(True), tensor(True), tensor(True), ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24027 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     src  \\\n",
       "0      [tensor(2), tensor(63), tensor(21), tensor(64)...   \n",
       "1      [tensor(2), tensor(543), tensor(18), tensor(40...   \n",
       "2      [tensor(2), tensor(641), tensor(2252), tensor(...   \n",
       "3      [tensor(2), tensor(543), tensor(18), tensor(41...   \n",
       "4      [tensor(2), tensor(6954), tensor(6166), tensor...   \n",
       "...                                                  ...   \n",
       "24022  [tensor(2), tensor(9679), tensor(2052), tensor...   \n",
       "24023  [tensor(2), tensor(63), tensor(21), tensor(64)...   \n",
       "24024  [tensor(2), tensor(4461), tensor(7315), tensor...   \n",
       "24025  [tensor(2), tensor(63), tensor(21), tensor(64)...   \n",
       "24026  [tensor(2), tensor(20223), tensor(2520), tenso...   \n",
       "\n",
       "                                                    clss  \\\n",
       "0      [tensor(0), tensor(17), tensor(46), tensor(66)...   \n",
       "1      [tensor(0), tensor(71), tensor(126), tensor(17...   \n",
       "2      [tensor(0), tensor(20), tensor(54), tensor(127...   \n",
       "3      [tensor(0), tensor(70), tensor(84), tensor(167...   \n",
       "4      [tensor(0), tensor(82), tensor(109), tensor(17...   \n",
       "...                                                  ...   \n",
       "24022  [tensor(0), tensor(88), tensor(124), tensor(13...   \n",
       "24023  [tensor(0), tensor(46), tensor(92), tensor(128...   \n",
       "24024  [tensor(0), tensor(32), tensor(95), tensor(112...   \n",
       "24025  [tensor(0), tensor(18), tensor(31), tensor(52)...   \n",
       "24026  [tensor(0), tensor(8), tensor(24), tensor(49),...   \n",
       "\n",
       "                                                    segs  \\\n",
       "0      [tensor(0), tensor(0), tensor(0), tensor(0), t...   \n",
       "1      [tensor(0), tensor(0), tensor(0), tensor(0), t...   \n",
       "2      [tensor(0), tensor(0), tensor(0), tensor(0), t...   \n",
       "3      [tensor(0), tensor(0), tensor(0), tensor(0), t...   \n",
       "4      [tensor(0), tensor(0), tensor(0), tensor(0), t...   \n",
       "...                                                  ...   \n",
       "24022  [tensor(0), tensor(0), tensor(0), tensor(0), t...   \n",
       "24023  [tensor(0), tensor(0), tensor(0), tensor(0), t...   \n",
       "24024  [tensor(0), tensor(0), tensor(0), tensor(0), t...   \n",
       "24025  [tensor(0), tensor(0), tensor(0), tensor(0), t...   \n",
       "24026  [tensor(0), tensor(0), tensor(0), tensor(0), t...   \n",
       "\n",
       "                                                    mask  \\\n",
       "0      [tensor(True), tensor(True), tensor(True), ten...   \n",
       "1      [tensor(True), tensor(True), tensor(True), ten...   \n",
       "2      [tensor(True), tensor(True), tensor(True), ten...   \n",
       "3      [tensor(True), tensor(True), tensor(True), ten...   \n",
       "4      [tensor(True), tensor(True), tensor(True), ten...   \n",
       "...                                                  ...   \n",
       "24022  [tensor(True), tensor(True), tensor(True), ten...   \n",
       "24023  [tensor(True), tensor(True), tensor(True), ten...   \n",
       "24024  [tensor(True), tensor(True), tensor(True), ten...   \n",
       "24025  [tensor(True), tensor(True), tensor(True), ten...   \n",
       "24026  [tensor(True), tensor(True), tensor(True), ten...   \n",
       "\n",
       "                                               mask_clss  \n",
       "0      [tensor(True), tensor(True), tensor(True), ten...  \n",
       "1      [tensor(True), tensor(True), tensor(True), ten...  \n",
       "2      [tensor(True), tensor(True), tensor(True), ten...  \n",
       "3      [tensor(True), tensor(True), tensor(True), ten...  \n",
       "4      [tensor(True), tensor(True), tensor(True), ten...  \n",
       "...                                                  ...  \n",
       "24022  [tensor(True), tensor(True), tensor(True), ten...  \n",
       "24023  [tensor(True), tensor(True), tensor(True), ten...  \n",
       "24024  [tensor(True), tensor(True), tensor(True), ten...  \n",
       "24025  [tensor(True), tensor(True), tensor(True), ten...  \n",
       "24026  [tensor(True), tensor(True), tensor(True), ten...  \n",
       "\n",
       "[24027 rows x 5 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95cfedcf-31c8-4f12-bed0-e1dddd884547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset..\n",
      "Loading valid dataset..\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_loaders(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b9e172c-9959-4a89-97d7-4d5630c4c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = None\n",
    "for sample in train_loader:\n",
    "    temp = sample\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dff1ca1-c032-4e94-a083-5ccaacb320e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,   63,   21,  ...,    0,    0,    0],\n",
       "        [   2, 5216, 2079,  ...,    0,    0,    0],\n",
       "        [   2, 9679, 2145,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   2,  543,   18,  ...,    0,    0,    0],\n",
       "        [   2,   63,   21,  ...,    0,    0,    0],\n",
       "        [   2, 9679, 7285,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# src\n",
    "temp[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "459ea8d3-58a3-4323-8abf-64df615470ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 47, 89,  ..., -1, -1, -1],\n",
       "        [ 0, 21, 52,  ..., -1, -1, -1],\n",
       "        [ 0, 20, 60,  ..., -1, -1, -1],\n",
       "        ...,\n",
       "        [ 0, 35, 71,  ..., -1, -1, -1],\n",
       "        [ 0, 20, 40,  ..., -1, -1, -1],\n",
       "        [ 0, 40, 59,  ..., -1, -1, -1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# segs\n",
    "temp[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1004be2f-3727-4caa-b611-edc4996dabcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clss\n",
    "temp[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "333cad5a-5bd6-424b-8018-83ec3529b0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask\n",
    "temp[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a69f2efb-428c-44fa-a15d-1c0cf4c5dd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask_clss\n",
    "temp[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67bf9f44-cbd2-49b0-9514-430b3a3c89aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 1,  ..., 0, 0, 0],\n",
       "        [1, 0, 0,  ..., 0, 0, 0],\n",
       "        [1, 0, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 1, 0,  ..., 0, 0, 0],\n",
       "        [0, 1, 0,  ..., 0, 0, 0],\n",
       "        [1, 0, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label\n",
    "temp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee05ad79-2712-4d83-a633-2e4622a4f3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
